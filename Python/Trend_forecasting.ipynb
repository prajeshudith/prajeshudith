{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trend_forecasting",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "#Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "from plotnine import *\n",
        "import streamlit as st\n",
        "from statsmodels.tools.eval_measures import rmse\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "##FOR SALES##\n",
        "#Importing the dataset\n",
        "df = pd.read_excel(r'/content/drive/MyDrive/Team Folder/Datasets/Book2_excel.xlsx')\n",
        "\n",
        "#Filtering only the required columns\n",
        "df2 = df[[\"Section\",\"Quantity\",\"Transaction_Date\"]]\n",
        "\n",
        "#Sorting by date\n",
        "df3 = df2.sort_values(by = \"Transaction_Date\")\n",
        "\n",
        "#Finding the total sales of ticket in a section per date\n",
        "df4 = df3.groupby(['Section','Transaction_Date'],as_index =  False)['Quantity'].sum()\n",
        "\n",
        "#Combing then Clubs\n",
        "club_1 = df4[df4.Section == \"Club Hall of Fame\"]\n",
        "club_2 = df4[df4.Section == \"Club Main\"]\n",
        "club_3 = df4[df4.Section == \"Club Mezzanine\"]\n",
        "club_4 = [club_1,club_2,club_3]\n",
        "club_5 = pd.concat(club_4)\n",
        "\n",
        "Club = club_5.groupby(['Transaction_Date'],as_index =  False)['Quantity'].sum()\n",
        "\n",
        "Club[\"Section\"] = \"Overall Club\"\n",
        "Club = Club[[\"Section\",\"Transaction_Date\",\"Quantity\"]]\n",
        "\n",
        "#Combining the Floors\n",
        "floor_1 = df4[df4.Section == \"FN5\"]\n",
        "floor_2 = df4[df4.Section == \"Floor FE\"]\n",
        "floor_3 = df4[df4.Section == \"Floor FN\"]\n",
        "floor_4 = df4[df4.Section == \"Floor FS\"]\n",
        "floor_5 = df4[df4.Section == \"Floor FW\"]\n",
        "floor_6 = [floor_1,floor_2,floor_3,floor_4,floor_5]\n",
        "floor_7 = pd.concat(floor_6)\n",
        "\n",
        "Floor = floor_7.groupby(['Transaction_Date'],as_index =  False)['Quantity'].sum()\n",
        "\n",
        "Floor[\"Section\"] = \"Overall Floor\"\n",
        "Floor = Floor[[\"Section\",\"Transaction_Date\",\"Quantity\"]]\n",
        "\n",
        "#Combing the Halls\n",
        "hall_1 = df4[df4.Section == \"Hall of Fame\"]\n",
        "hall_2 = df4[df4.Section == \"Hall of Fame Suite\"]\n",
        "hall_3 = [hall_1,hall_2]\n",
        "hall_4 = pd.concat(hall_3)\n",
        "\n",
        "Hall = hall_4.groupby(['Transaction_Date'],as_index =  False)['Quantity'].sum()\n",
        "\n",
        "Hall[\"Section\"] = \"Overall Hall\"\n",
        "Hall = Hall[[\"Section\",\"Transaction_Date\",\"Quantity\"]]\n",
        "\n",
        "#Appending with the Old dataframe\n",
        "df5 =[df4,Club,Floor,Hall]\n",
        "df6 = pd.concat(df5)\n",
        "\n",
        "#Heading\n",
        "st.title(\"Trend Visualisation for sales of tickets\")\n",
        "\n",
        "#Selecting the section\n",
        "section = st.sidebar.multiselect('Select a Sections',list(df6.Section.unique()))\n",
        "\n",
        "#Start date\n",
        "start_date = st.sidebar.date_input('Select the Start date',value =pd.to_datetime(\"2021-03-23\", format=\"%Y-%m-%d\") ,min_value = pd.to_datetime(\"2021-03-23\", format=\"%Y-%m-%d\"),max_value=pd.to_datetime(\"2021-05-10\", format=\"%Y-%m-%d\"))\n",
        "\n",
        "#End date\n",
        "end_date = st.sidebar.date_input('Select the End date',value =pd.to_datetime(\"2021-03-23\", format=\"%Y-%m-%d\") ,min_value = pd.to_datetime(\"2021-03-23\", format=\"%Y-%m-%d\"),max_value=pd.to_datetime(\"2021-05-10\", format=\"%Y-%m-%d\"))\n",
        "\n",
        "#Converting the date as string\n",
        "start = start_date.strftime(\"%Y-%m-%d\")\n",
        "end = end_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "#Filtering with the input date\n",
        "df8 = df6.loc[(df6[\"Transaction_Date\"]>= start)&(df6[\"Transaction_Date\"]<= end)]\n",
        "\n",
        "#Filtering with input sections\n",
        "names = section\n",
        "df9 = df8[df8.Section.isin(names)]\n",
        "\n",
        "#Selecting only dates and sales\n",
        "df10 = df9[[\"Transaction_Date\",\"Quantity\"]]\n",
        "\n",
        "#Converting dates as datetime format\n",
        "df10.Transaction_Date = pd.to_datetime(df10.Transaction_Date)\n",
        "\n",
        "#Converting date column as index\n",
        "df11 = df10.set_index(\"Transaction_Date\")\n",
        "\n",
        "#Putting the dataframe into a variable \"train\"\n",
        "train = df11\n",
        "\n",
        "#Model fitting for prediction\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train)\n",
        "train = scaler.transform(train)\n",
        "\n",
        "n_input = 6\n",
        "n_features = 1\n",
        "generator = TimeseriesGenerator(train, train, length=n_input, batch_size=6)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', input_shape=(n_input, n_features)))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model.fit_generator(generator,epochs=6)\n",
        "\n",
        "pred_list = []\n",
        "\n",
        "batch = train[-n_input:].reshape((1, n_input, n_features))\n",
        "\n",
        "for i in range(n_input):   \n",
        "    pred_list.append(model.predict(batch)[0]) \n",
        "    batch = np.append(batch[:,1:,:],[[pred_list[i]]],axis=1)\n",
        "\n",
        "from pandas.tseries.offsets import DateOffset\n",
        "add_dates = [df11.index[-1] + DateOffset(days = x) for x in range(0,7) ]\n",
        "future_dates = pd.DataFrame(index=add_dates[1:],columns=df11.columns)\n",
        "\n",
        "df_predict = pd.DataFrame(scaler.inverse_transform(pred_list),\n",
        "                          index=future_dates[-n_input:].index, columns=['Prediction'])\n",
        "\n",
        "df_proj = pd.concat([df11,df_predict], axis=1)\n",
        "\n",
        "#Visualising the prediction graph\n",
        "fig = px.scatter(df_proj,\n",
        "    trendline_color_override='green'\n",
        "                 \n",
        ")\n",
        "\n",
        "fig.update_traces(mode = 'lines')\n",
        "\n",
        "#Editing date for acutual data including next 6 days\n",
        "end_2 = end_date + DateOffset(days = 6)\n",
        "\n",
        "#Filtering the data according to date (+6 days from the end date selected for prediction)\n",
        "df12 = df6.loc[(df6[\"Transaction_Date\"]>= start)&(df6[\"Transaction_Date\"]<= end_2)]\n",
        "\n",
        "#Filtering the sections\n",
        "df13 = df12[df12.Section.isin(names)]\n",
        "\n",
        "#Plotting the acutal sales\n",
        "fig2 = px.scatter(df13,x=\"Transaction_Date\",\n",
        "    y=\"Quantity\",\n",
        "    trendline=\"ols\",\n",
        "    trendline_color_override='green',\n",
        "    color=\"Section\"\n",
        "                 \n",
        ")\n",
        "\n",
        "fig2.update_traces(mode = 'lines')\n",
        "\n",
        "#Editing date for acutual data for excat dates\n",
        "\n",
        "#Filtering the data according to date (+6 days from the end date selected for prediction)\n",
        "df21 = df6.loc[(df6[\"Transaction_Date\"]>= start)&(df6[\"Transaction_Date\"]<= end)]\n",
        "\n",
        "#Filtering the sections\n",
        "df22 = df21[df21.Section.isin(names)]\n",
        "\n",
        "#Plotting the acutal sales\n",
        "fig4 = px.scatter(df22,x=\"Transaction_Date\",\n",
        "    y=\"Quantity\",\n",
        "    trendline=\"ols\",\n",
        "    trendline_color_override='green',\n",
        "    color=\"Section\"\n",
        "                 \n",
        ")\n",
        "\n",
        "fig4.update_traces(mode = 'lines')\n",
        "\n",
        "##FOR PRICE##\n",
        "\n",
        "#Filtering only the required columns\n",
        "df14 = df[[\"Section\",\"Display_Price_Per_Ticket_Amount\",\"Transaction_Date\"]]\n",
        "\n",
        "#Sorting by date\n",
        "df15 = df14.sort_values(by = \"Transaction_Date\")\n",
        "\n",
        "#Finding the mean price of ticket in a section per date\n",
        "df16 = df15.groupby(['Section','Transaction_Date'],as_index =  False)['Display_Price_Per_Ticket_Amount'].mean()\n",
        "\n",
        "#Combing then Clubs\n",
        "club_6 = df16[df16.Section == \"Club Hall of Fame\"]\n",
        "club_7 = df16[df16.Section == \"Club Main\"]\n",
        "club_8 = df16[df16.Section == \"Club Mezzanine\"]\n",
        "club_9 = [club_6,club_7,club_8]\n",
        "club_10 = pd.concat(club_9)\n",
        "\n",
        "Club_11 = club_10.groupby(['Transaction_Date'],as_index =  False)['Display_Price_Per_Ticket_Amount'].mean()\n",
        "\n",
        "Club_11[\"Section\"] = \"Overall Club\"\n",
        "Club_12 = Club_11[[\"Section\",\"Transaction_Date\",\"Display_Price_Per_Ticket_Amount\"]]\n",
        "\n",
        "#Combining the Floors\n",
        "floor_8 = df16[df16.Section == \"FN5\"]\n",
        "floor_9 = df16[df16.Section == \"Floor FE\"]\n",
        "floor_10 = df16[df16.Section == \"Floor FN\"]\n",
        "floor_11 = df16[df16.Section == \"Floor FS\"]\n",
        "floor_12 = df16[df16.Section == \"Floor FW\"]\n",
        "floor_13 = [floor_8,floor_9,floor_10,floor_11,floor_12]\n",
        "floor_14 = pd.concat(floor_13)\n",
        "\n",
        "Floor_15 = floor_14.groupby(['Transaction_Date'],as_index =  False)['Display_Price_Per_Ticket_Amount'].mean()\n",
        "\n",
        "Floor_15[\"Section\"] = \"Overall Floor\"\n",
        "Floor_16 = Floor_15[[\"Section\",\"Transaction_Date\",\"Display_Price_Per_Ticket_Amount\"]]\n",
        "\n",
        "#Combing the Halls\n",
        "hall_5 = df16[df16.Section == \"Hall of Fame\"]\n",
        "hall_6 = df16[df16.Section == \"Hall of Fame Suite\"]\n",
        "hall_7 = [hall_5,hall_6]\n",
        "hall_8 = pd.concat(hall_7)\n",
        "\n",
        "Hall_9 = hall_8.groupby(['Transaction_Date'],as_index =  False)['Display_Price_Per_Ticket_Amount'].mean()\n",
        "\n",
        "Hall_9[\"Section\"] = \"Overall Hall\"\n",
        "Hall_10 = Hall_9[[\"Section\",\"Transaction_Date\",\"Display_Price_Per_Ticket_Amount\"]]\n",
        "\n",
        "#Appending with the Old dataframe\n",
        "df17 =[df16,Club_12,Floor_16,Hall_10]\n",
        "df18 = pd.concat(df17)\n",
        "\n",
        "#Filtering the data according to date (+6 days from the end date selected for prediction)\n",
        "df19 = df18.loc[(df18[\"Transaction_Date\"]>= start)&(df18[\"Transaction_Date\"]<= end_2)]\n",
        "\n",
        "#Filtering the sections\n",
        "df20 = df19[df19.Section.isin(names)]\n",
        "\n",
        "#Ploting the graph\n",
        "fig3 = px.scatter(df20,\n",
        "    x=\"Transaction_Date\",\n",
        "    y=\"Display_Price_Per_Ticket_Amount\",\n",
        "    trendline=\"ols\",\n",
        "    trendline_color_override='green',\n",
        "    color=\"Section\"\n",
        "                 \n",
        ")\n",
        "\n",
        "fig3.update_traces(mode = 'lines')\n",
        "\n",
        "#Plotting all the graphs\n",
        "st.plotly_chart(fig4, use_container_width=True)\n",
        "st.plotly_chart(fig, use_container_width=True)\n",
        "st.plotly_chart(fig2, use_container_width=True)\n",
        "st.plotly_chart(fig3, use_container_width=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3UUFo345SRx",
        "outputId": "532c8798-232b-44a1-81e0-091961e1d9cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPxKWJ1T3AWX",
        "outputId": "526bbaca-9644-4981-c166-75f694af6843"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-04 11:49:23.990 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.177.159:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.029s\n",
            "your url is: https://shaggy-walls-do-34-125-177-159.loca.lt\n",
            "2022-05-04 11:49:59.526 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 114, in <module>\n",
            "    scaler.fit(train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 416, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 458, in partial_fit\n",
            "    force_all_finite=\"allow-nan\",\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 566, in _validate_data\n",
            "    X = check_array(X, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "2022-05-04 11:50:03.567 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 119, in <module>\n",
            "    generator = TimeseriesGenerator(train, train, length=n_input, batch_size=6)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/sequence.py\", line 357, in __init__\n",
            "    % (self.start_index, self.end_index))\n",
            "ValueError: `start_index+length=6 > end_index=0` is disallowed, as no part of the sequence would be left to be used as current step.\n",
            "\n",
            "2022-05-04 11:50:06.515 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 114, in <module>\n",
            "    scaler.fit(train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 416, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 458, in partial_fit\n",
            "    force_all_finite=\"allow-nan\",\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 566, in _validate_data\n",
            "    X = check_array(X, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "2022-05-04 11:50:10.157526: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Epoch 1/6\n",
            "3/3 [==============================] - 2s 23ms/step - loss: 0.1937\n",
            "Epoch 2/6\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1694\n",
            "Epoch 3/6\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1503\n",
            "Epoch 4/6\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1294\n",
            "Epoch 5/6\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1129\n",
            "Epoch 6/6\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0981\n",
            "Epoch 1/6\n",
            "3/3 [==============================] - 1s 8ms/step - loss: 0.1949\n",
            "Epoch 2/6\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1691\n",
            "Epoch 3/6\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1502\n",
            "Epoch 4/6\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1379\n",
            "Epoch 5/6\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1116\n",
            "Epoch 6/6\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1004\n",
            "2022-05-04 11:56:35.674 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 114, in <module>\n",
            "    scaler.fit(train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 416, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 458, in partial_fit\n",
            "    force_all_finite=\"allow-nan\",\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 566, in _validate_data\n",
            "    X = check_array(X, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "2022-05-04 11:56:43.768 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 119, in <module>\n",
            "    generator = TimeseriesGenerator(train, train, length=n_input, batch_size=6)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/sequence.py\", line 357, in __init__\n",
            "    % (self.start_index, self.end_index))\n",
            "ValueError: `start_index+length=6 > end_index=0` is disallowed, as no part of the sequence would be left to be used as current step.\n",
            "\n",
            "2022-05-04 11:56:46.843 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 119, in <module>\n",
            "    generator = TimeseriesGenerator(train, train, length=n_input, batch_size=6)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/sequence.py\", line 357, in __init__\n",
            "    % (self.start_index, self.end_index))\n",
            "ValueError: `start_index+length=6 > end_index=4` is disallowed, as no part of the sequence would be left to be used as current step.\n",
            "\n",
            "2022-05-04 11:56:56.217 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 119, in <module>\n",
            "    generator = TimeseriesGenerator(train, train, length=n_input, batch_size=6)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/sequence.py\", line 357, in __init__\n",
            "    % (self.start_index, self.end_index))\n",
            "ValueError: `start_index+length=6 > end_index=3` is disallowed, as no part of the sequence would be left to be used as current step.\n",
            "\n",
            "Epoch 1/6\n",
            "1/1 [==============================] - 1s 1s/step - loss: 9.5551e-06\n",
            "Epoch 2/6\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.0910e-05\n",
            "Epoch 3/6\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.9562e-05\n",
            "Epoch 4/6\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2360e-05\n",
            "Epoch 5/6\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.2282e-05\n",
            "Epoch 6/6\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.1300e-05\n",
            "2022-05-04 11:57:03.821 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 114, in <module>\n",
            "    scaler.fit(train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 416, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 458, in partial_fit\n",
            "    force_all_finite=\"allow-nan\",\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 566, in _validate_data\n",
            "    X = check_array(X, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "2022-05-04 11:57:06.920 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 119, in <module>\n",
            "    generator = TimeseriesGenerator(train, train, length=n_input, batch_size=6)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/sequence.py\", line 357, in __init__\n",
            "    % (self.start_index, self.end_index))\n",
            "ValueError: `start_index+length=6 > end_index=0` is disallowed, as no part of the sequence would be left to be used as current step.\n",
            "\n",
            "2022-05-04 11:57:40.190 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 114, in <module>\n",
            "    scaler.fit(train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 416, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 458, in partial_fit\n",
            "    force_all_finite=\"allow-nan\",\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 566, in _validate_data\n",
            "    X = check_array(X, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "Epoch 1/6\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1967\n",
            "Epoch 2/6\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1895\n",
            "Epoch 3/6\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1783\n",
            "Epoch 4/6\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1732\n",
            "Epoch 5/6\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1660\n",
            "Epoch 6/6\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1588\n",
            "2022-05-04 11:58:23.177 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 114, in <module>\n",
            "    scaler.fit(train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 416, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 458, in partial_fit\n",
            "    force_all_finite=\"allow-nan\",\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 566, in _validate_data\n",
            "    X = check_array(X, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "Epoch 1/6\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.7163e-06\n",
            "Epoch 2/6\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.2426e-05\n",
            "Epoch 3/6\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7694e-05\n",
            "Epoch 4/6\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 5.1529e-06\n",
            "Epoch 5/6\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.2352e-05\n",
            "Epoch 6/6\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.7519e-05\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 10ms/step - loss: 0.0868\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0782\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0677\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0620\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0624\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0607\n",
            "2022-05-04 11:58:44.248 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 144, in <module>\n",
            "    df_proj = pd.concat([df11,df_predict], axis=1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 307, in concat\n",
            "    return op.get_result()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 528, in get_result\n",
            "    indexers[ax] = obj_labels.get_indexer(new_labels)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\", line 3442, in get_indexer\n",
            "    raise InvalidIndexError(self._requires_unique_msg)\n",
            "pandas.errors.InvalidIndexError: Reindexing only valid with uniquely valued Index objects\n",
            "\n",
            "Epoch 1/6\n",
            "3/3 [==============================] - 2s 8ms/step - loss: 0.0190\n",
            "Epoch 2/6\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0118\n",
            "Epoch 3/6\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0086\n",
            "Epoch 4/6\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.0064\n",
            "Epoch 5/6\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0059\n",
            "Epoch 6/6\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.0054\n",
            "2022-05-04 12:03:59.645 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 114, in <module>\n",
            "    scaler.fit(train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 416, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 458, in partial_fit\n",
            "    force_all_finite=\"allow-nan\",\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 566, in _validate_data\n",
            "    X = check_array(X, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "Epoch 1/6\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.2512e-06\n",
            "Epoch 2/6\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 7.9077e-05\n",
            "Epoch 3/6\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.6841e-05\n",
            "Epoch 4/6\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.3146e-05\n",
            "Epoch 5/6\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.3291e-05\n",
            "Epoch 6/6\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 8.8569e-06\n",
            "2022-05-04 12:04:32.857 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 114, in <module>\n",
            "    scaler.fit(train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 416, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 458, in partial_fit\n",
            "    force_all_finite=\"allow-nan\",\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 566, in _validate_data\n",
            "    X = check_array(X, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 10ms/step - loss: 0.1941\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1546\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1126\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0872\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0993\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0907\n",
            "Epoch 1/6\n",
            "3/3 [==============================] - 1s 9ms/step - loss: 0.1866\n",
            "Epoch 2/6\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1538\n",
            "Epoch 3/6\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1220\n",
            "Epoch 4/6\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0940\n",
            "Epoch 5/6\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.0712\n",
            "Epoch 6/6\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0761\n",
            "Epoch 1/6\n",
            "3/3 [==============================] - 1s 9ms/step - loss: 0.0213\n",
            "Epoch 2/6\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0143\n",
            "Epoch 3/6\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0110\n",
            "Epoch 4/6\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0068\n",
            "Epoch 5/6\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 6/6\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0059\n",
            "Epoch 1/6\n",
            "3/3 [==============================] - 1s 11ms/step - loss: 0.1895\n",
            "Epoch 2/6\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1532\n",
            "Epoch 3/6\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1113\n",
            "Epoch 4/6\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0858\n",
            "Epoch 5/6\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0749\n",
            "Epoch 6/6\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0766\n",
            "Epoch 1/6\n",
            "3/3 [==============================] - 1s 10ms/step - loss: 0.2062\n",
            "Epoch 2/6\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1689\n",
            "Epoch 3/6\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1398\n",
            "Epoch 4/6\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1087\n",
            "Epoch 5/6\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0795\n",
            "Epoch 6/6\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0679\n",
            "2022-05-04 12:21:08.209 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 114, in <module>\n",
            "    scaler.fit(train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 416, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 458, in partial_fit\n",
            "    force_all_finite=\"allow-nan\",\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 566, in _validate_data\n",
            "    X = check_array(X, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "Epoch 1/6\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 0.0333\n",
            "Epoch 2/6\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0240\n",
            "Epoch 3/6\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0174\n",
            "Epoch 4/6\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0139\n",
            "Epoch 5/6\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0114\n",
            "Epoch 6/6\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0123\n",
            "Epoch 1/6\n",
            "2/2 [==============================] - 1s 11ms/step - loss: 0.0308\n",
            "Epoch 2/6\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0224\n",
            "Epoch 3/6\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0159\n",
            "Epoch 4/6\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0120\n",
            "Epoch 5/6\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0100\n",
            "Epoch 6/6\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0118\n",
            "2022-05-04 12:31:38.485 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 114, in <module>\n",
            "    scaler.fit(train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 416, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 458, in partial_fit\n",
            "    force_all_finite=\"allow-nan\",\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 566, in _validate_data\n",
            "    X = check_array(X, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "2022-05-04 12:31:44.580 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 119, in <module>\n",
            "    generator = TimeseriesGenerator(train, train, length=n_input, batch_size=6)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/sequence.py\", line 357, in __init__\n",
            "    % (self.start_index, self.end_index))\n",
            "ValueError: `start_index+length=6 > end_index=0` is disallowed, as no part of the sequence would be left to be used as current step.\n",
            "\n",
            "Epoch 1/6\n",
            "2/2 [==============================] - 1s 10ms/step - loss: 0.1403\n",
            "Epoch 2/6\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1248\n",
            "Epoch 3/6\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1068\n",
            "Epoch 4/6\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0959\n",
            "Epoch 5/6\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0788\n",
            "Epoch 6/6\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0708\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}